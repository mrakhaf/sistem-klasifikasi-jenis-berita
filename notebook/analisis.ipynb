{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dokumen</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Presenter Raffi Ahmad baru saja membeli mobil ...</td>\n",
       "      <td>entertaiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pedangdut Ayu Ting Ting memang selalu menjadi ...</td>\n",
       "      <td>entertaiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lucinta Luna begitu percaya diri akan kecantik...</td>\n",
       "      <td>entertaiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucinta Luna kembali menyita perhatian dengan ...</td>\n",
       "      <td>entertaiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atlet badminton, Loh Kean Yew saat ini tengah...</td>\n",
       "      <td>entertaiment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dokumen         label\n",
       "0  Presenter Raffi Ahmad baru saja membeli mobil ...  entertaiment\n",
       "1  Pedangdut Ayu Ting Ting memang selalu menjadi ...  entertaiment\n",
       "2  Lucinta Luna begitu percaya diri akan kecantik...  entertaiment\n",
       "3  Lucinta Luna kembali menyita perhatian dengan ...  entertaiment\n",
       "4   Atlet badminton, Loh Kean Yew saat ini tengah...  entertaiment"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '..\\data\\data_berita.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df[['dokumen','label']].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing all\n",
    "\n",
    "def case_folding(str_data):\n",
    "    return str_data.lower()\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "def tokenizing(str_data):\n",
    "    return (word_tokenize(str_data))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopword_id = stopwords.words('indonesian')\n",
    "stopword_en = stopwords.words('english')\n",
    "stopword_all = stopword_id + stopword_en\n",
    "def stopword_removal(list_str_data):\n",
    "    list_str_data_t = []\n",
    "    for s in list_str_data:\n",
    "        if (s not in stopword_all) & s.isalpha():\n",
    "            list_str_data_t.append(s)\n",
    "    return list_str_data_t\n",
    "\n",
    "def preprocessing(str_data):\n",
    "    str_data_t = case_folding(str_data)\n",
    "    str_data_t = tokenizing(str_data_t)\n",
    "    str_data_t = stopword_removal(str_data_t)\n",
    "    str_data_t = ' '.join(str_data_t)\n",
    "    return str_data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessing'] = df.dokumen.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dokumen</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Presenter Raffi Ahmad baru saja membeli mobil ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>presenter raffi ahmad membeli mobil mewah roll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pedangdut Ayu Ting Ting memang selalu menjadi ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>pedangdut ayu ting ting sorotan publik terkini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lucinta Luna begitu percaya diri akan kecantik...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>lucinta luna percaya kecantikannya lucinta men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucinta Luna kembali menyita perhatian dengan ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>lucinta luna menyita perhatian penampilan cant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atlet badminton, Loh Kean Yew saat ini tengah...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>atlet badminton loh kean yew perbincangan kala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dokumen         label  \\\n",
       "0  Presenter Raffi Ahmad baru saja membeli mobil ...  entertaiment   \n",
       "1  Pedangdut Ayu Ting Ting memang selalu menjadi ...  entertaiment   \n",
       "2  Lucinta Luna begitu percaya diri akan kecantik...  entertaiment   \n",
       "3  Lucinta Luna kembali menyita perhatian dengan ...  entertaiment   \n",
       "4   Atlet badminton, Loh Kean Yew saat ini tengah...  entertaiment   \n",
       "\n",
       "                                       preprocessing  \n",
       "0  presenter raffi ahmad membeli mobil mewah roll...  \n",
       "1  pedangdut ayu ting ting sorotan publik terkini...  \n",
       "2  lucinta luna percaya kecantikannya lucinta men...  \n",
       "3  lucinta luna menyita perhatian penampilan cant...  \n",
       "4  atlet badminton loh kean yew perbincangan kala...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def generate_ngrams(s, n):\n",
    "    # Convert to lowercases\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Replace all none alphanumeric characters with spaces\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    \n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    \n",
    "    # Use the zip function to help us generate n-grams\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    a = [\" \".join(ngram) for ngram in ngrams]\n",
    "    return a\n",
    "\n",
    "def n_gram(data):\n",
    "    # Generate n-grams\n",
    "    unigram = generate_ngrams(data, 1)\n",
    "    bigram = generate_ngrams(data, 2)\n",
    "    trigram = generate_ngrams(data, 3)\n",
    "\n",
    "    data = [\n",
    "        unigram,\n",
    "        bigram,\n",
    "        trigram\n",
    "    ]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bigram'] = df.preprocessing.apply(lambda x:n_gram(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dokumen</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Presenter Raffi Ahmad baru saja membeli mobil ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>presenter raffi ahmad membeli mobil mewah roll...</td>\n",
       "      <td>[presenter raffi, raffi ahmad, ahmad membeli, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pedangdut Ayu Ting Ting memang selalu menjadi ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>pedangdut ayu ting ting sorotan publik terkini...</td>\n",
       "      <td>[pedangdut ayu, ayu ting, ting ting, ting soro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lucinta Luna begitu percaya diri akan kecantik...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>lucinta luna percaya kecantikannya lucinta men...</td>\n",
       "      <td>[lucinta luna, luna percaya, percaya kecantika...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucinta Luna kembali menyita perhatian dengan ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>lucinta luna menyita perhatian penampilan cant...</td>\n",
       "      <td>[lucinta luna, luna menyita, menyita perhatian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atlet badminton, Loh Kean Yew saat ini tengah...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>atlet badminton loh kean yew perbincangan kala...</td>\n",
       "      <td>[atlet badminton, badminton loh, loh kean, kea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dokumen         label  \\\n",
       "0  Presenter Raffi Ahmad baru saja membeli mobil ...  entertaiment   \n",
       "1  Pedangdut Ayu Ting Ting memang selalu menjadi ...  entertaiment   \n",
       "2  Lucinta Luna begitu percaya diri akan kecantik...  entertaiment   \n",
       "3  Lucinta Luna kembali menyita perhatian dengan ...  entertaiment   \n",
       "4   Atlet badminton, Loh Kean Yew saat ini tengah...  entertaiment   \n",
       "\n",
       "                                       preprocessing  \\\n",
       "0  presenter raffi ahmad membeli mobil mewah roll...   \n",
       "1  pedangdut ayu ting ting sorotan publik terkini...   \n",
       "2  lucinta luna percaya kecantikannya lucinta men...   \n",
       "3  lucinta luna menyita perhatian penampilan cant...   \n",
       "4  atlet badminton loh kean yew perbincangan kala...   \n",
       "\n",
       "                                              bigram  \n",
       "0  [presenter raffi, raffi ahmad, ahmad membeli, ...  \n",
       "1  [pedangdut ayu, ayu ting, ting ting, ting soro...  \n",
       "2  [lucinta luna, luna percaya, percaya kecantika...  \n",
       "3  [lucinta luna, luna menyita, menyita perhatian...  \n",
       "4  [atlet badminton, badminton loh, loh kean, kea...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mpu\n",
    "\n",
    "def creating_bag_of_word(doc_l):\n",
    "    bag =[]\n",
    "    for i in doc_l:\n",
    "        bag.extend(i)\n",
    "    bag_of_word = list(set(bag))\n",
    "    # print('jumlah term')\n",
    "    # print(len(bag_of_word))\n",
    "    bag_of_word.sort()\n",
    "    return(bag_of_word)\n",
    "\n",
    "def count_doc_freq(bow, doc_l):\n",
    "    document_frequency = {}\n",
    "    for b in bow:\n",
    "        count_df = 0\n",
    "        for d in doc_l:\n",
    "            if b in d : count_df+=1           \n",
    "        document_frequency[b] = count_df\n",
    "    return document_frequency\n",
    "\n",
    "def count_inv_doc_freq(doc_freq, doc_l):\n",
    "    log_document_frequency = {}\n",
    "    for k,v in doc_freq.items():\n",
    "        log_document_frequency[k] = math.log10(len(doc_l)/v)\n",
    "    return log_document_frequency\n",
    "\n",
    "def count_log_term_freq(bow, doc_l):\n",
    "    log_term_frequency = {}\n",
    "    for b in bow:\n",
    "        log_term_frequency[b] = {}\n",
    "        for index,d in enumerate(doc_l):\n",
    "            tfd = d.count(b)\n",
    "            if tfd == 0:\n",
    "                log_term_frequency[b][index] = 0\n",
    "            else :\n",
    "                log_term_frequency[b][index] = 1 + math.log10(tfd)\n",
    "    return log_term_frequency\n",
    "\n",
    "def count_tfidf(document_l):\n",
    "    '''\n",
    "    document_l : list dari dokumen yang sudah menjadi list dari ngram\n",
    "\n",
    "    '''\n",
    "    doc_l = document_l\n",
    "    bag_of_word = creating_bag_of_word(doc_l)\n",
    "    doc_freq = count_doc_freq(bag_of_word,doc_l) \n",
    "    idf = count_inv_doc_freq(doc_freq,doc_l) \n",
    "    tf = count_log_term_freq(bag_of_word,doc_l) \n",
    "    tfidf = tf\n",
    "\n",
    "    # mpu.io.write('bag_of_word.pickle', bag_of_word)\n",
    "    # mpu.io.write('idf.pickle', idf)\n",
    "\n",
    "    # read pickle\n",
    "    # unserialized_data = mpu.io.read('idf.pickle')\n",
    "\n",
    "    for k in tf.keys():\n",
    "        for i in tfidf[k].keys():\n",
    "            tfidf[k][i] = tfidf[k][i] * idf[k]\n",
    "    # tfidf = count_tfidf(df.bigram.tolist())\n",
    "    df_tfidf = pd.DataFrame(tfidf)\n",
    "    list_tfidf = df_tfidf.to_numpy().tolist()\n",
    "    return list_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpu\n",
    "# mpu.io.read('idf.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tfidf'] = count_tfidf(df.bigram.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dokumen</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>bigram</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Presenter Raffi Ahmad baru saja membeli mobil ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>presenter raffi ahmad membeli mobil mewah roll...</td>\n",
       "      <td>[presenter raffi, raffi ahmad, ahmad membeli, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pedangdut Ayu Ting Ting memang selalu menjadi ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>pedangdut ayu ting ting sorotan publik terkini...</td>\n",
       "      <td>[pedangdut ayu, ayu ting, ting ting, ting soro...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lucinta Luna begitu percaya diri akan kecantik...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>lucinta luna percaya kecantikannya lucinta men...</td>\n",
       "      <td>[lucinta luna, luna percaya, percaya kecantika...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucinta Luna kembali menyita perhatian dengan ...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>lucinta luna menyita perhatian penampilan cant...</td>\n",
       "      <td>[lucinta luna, luna menyita, menyita perhatian...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atlet badminton, Loh Kean Yew saat ini tengah...</td>\n",
       "      <td>entertaiment</td>\n",
       "      <td>atlet badminton loh kean yew perbincangan kala...</td>\n",
       "      <td>[atlet badminton, badminton loh, loh kean, kea...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dokumen         label  \\\n",
       "0  Presenter Raffi Ahmad baru saja membeli mobil ...  entertaiment   \n",
       "1  Pedangdut Ayu Ting Ting memang selalu menjadi ...  entertaiment   \n",
       "2  Lucinta Luna begitu percaya diri akan kecantik...  entertaiment   \n",
       "3  Lucinta Luna kembali menyita perhatian dengan ...  entertaiment   \n",
       "4   Atlet badminton, Loh Kean Yew saat ini tengah...  entertaiment   \n",
       "\n",
       "                                       preprocessing  \\\n",
       "0  presenter raffi ahmad membeli mobil mewah roll...   \n",
       "1  pedangdut ayu ting ting sorotan publik terkini...   \n",
       "2  lucinta luna percaya kecantikannya lucinta men...   \n",
       "3  lucinta luna menyita perhatian penampilan cant...   \n",
       "4  atlet badminton loh kean yew perbincangan kala...   \n",
       "\n",
       "                                              bigram  \\\n",
       "0  [presenter raffi, raffi ahmad, ahmad membeli, ...   \n",
       "1  [pedangdut ayu, ayu ting, ting ting, ting soro...   \n",
       "2  [lucinta luna, luna percaya, percaya kecantika...   \n",
       "3  [lucinta luna, luna menyita, menyita perhatian...   \n",
       "4  [atlet badminton, badminton loh, loh kean, kea...   \n",
       "\n",
       "                                               tfidf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.301...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "entertaiment       0.67      1.00      0.80         2\n",
      "    olahraga       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.tfidf.tolist(), df.label, test_size=0.2, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['entertaiment'], dtype='<U12')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict([df.iloc[1].tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probality untuk label entertaiment : \n",
      "1.0\n",
      "Probality untuk label olahraga : \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "proba = gnb.predict_proba([df.iloc[1].tfidf])[0]\n",
    "print('Probality untuk label entertaiment : ')\n",
    "print(proba[0])\n",
    "print('Probality untuk label olahraga : ')\n",
    "print(proba[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "predict\n",
      "entertaiment\n",
      "Probality untuk label entertaiment : \n",
      "1.0\n",
      "Probality untuk label olahraga : \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "saved_model_path = 'naivebayes_model.sav'\n",
    "loaded_model = joblib.load(saved_model_path)\n",
    "data = [df.iloc[1].tfidf]\n",
    "proba = loaded_model.predict_proba(data)[0]\n",
    "data = loaded_model.predict(data)[0]\n",
    "print()\n",
    "print()\n",
    "print('predict')\n",
    "print(data)\n",
    "print('Probality untuk label entertaiment : ')\n",
    "print(proba[0])\n",
    "print('Probality untuk label olahraga : ')\n",
    "print(proba[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save the model to disk\n",
    "filename = 'naivebayes_model.sav'\n",
    "joblib.dump(gnb, filename)\n",
    "  \n",
    "# load the model from disk\n",
    "# loaded_model = joblib.load(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343f3d274de0554954cf955edb183fdc0cc62c5d26a777b2092a313e42e0680b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
